{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4877104,"sourceType":"datasetVersion","datasetId":2827948}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":11.75988,"end_time":"2024-06-08T20:37:30.966706","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-06-08T20:37:19.206826","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"papermill":{"duration":0.993883,"end_time":"2024-06-08T20:37:23.330648","exception":false,"start_time":"2024-06-08T20:37:22.336765","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T21:02:54.805197Z","iopub.execute_input":"2024-06-09T21:02:54.806729Z","iopub.status.idle":"2024-06-09T21:02:54.819732Z","shell.execute_reply.started":"2024-06-09T21:02:54.806647Z","shell.execute_reply":"2024-06-09T21:02:54.818318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/online-retail-dataset/online_retail.csv', encoding='ISO-8859-1')\nprint(df.head())\nprint(df.dtypes)","metadata":{"papermill":{"duration":2.156193,"end_time":"2024-06-08T20:37:25.490614","exception":false,"start_time":"2024-06-08T20:37:23.334421","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T21:02:54.822569Z","iopub.execute_input":"2024-06-09T21:02:54.823107Z","iopub.status.idle":"2024-06-09T21:02:55.697653Z","shell.execute_reply.started":"2024-06-09T21:02:54.823061Z","shell.execute_reply":"2024-06-09T21:02:55.696380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DATA CLEANING\ndf.dropna(inplace=True)\ndf.drop_duplicates(inplace=True)\ndf['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\nprint(df.dtypes)","metadata":{"papermill":{"duration":0.826868,"end_time":"2024-06-08T20:37:26.322305","exception":false,"start_time":"2024-06-08T20:37:25.495437","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T21:02:55.698920Z","iopub.execute_input":"2024-06-09T21:02:55.699241Z","iopub.status.idle":"2024-06-09T21:02:56.217161Z","shell.execute_reply.started":"2024-06-09T21:02:55.699213Z","shell.execute_reply":"2024-06-09T21:02:56.215971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['TotalAmount'] = df['Quantity'] * df['UnitPrice']\nreference_date = df['InvoiceDate'].max() + pd.DateOffset(1)\ndf['last_purchase_date'] = (reference_date - df['InvoiceDate']).dt.days\n\ndf['Frequency'] = df.groupby('CustomerID')['InvoiceNo'].transform('nunique')","metadata":{"papermill":{"duration":0.046671,"end_time":"2024-06-08T20:37:26.372393","exception":false,"start_time":"2024-06-08T20:37:26.325722","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T21:15:35.770451Z","iopub.execute_input":"2024-06-09T21:15:35.771648Z","iopub.status.idle":"2024-06-09T21:15:35.843003Z","shell.execute_reply.started":"2024-06-09T21:15:35.771602Z","shell.execute_reply":"2024-06-09T21:15:35.841765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.histplot(df['last_purchase_date'], kde = True)\nplt.title('Distribution of last purchase dates')\nplt.show()\n\nplt.figure(figsize=(12, 6))\nsns.kdeplot(df['last_purchase_date'], shade=True)\nplt.title('Distribution of last purchase dates')\nplt.show()\n\nsns.histplot(df['Frequency'], kde=True)\nplt.title('Distribution of Frequency')\nplt.xlabel('Frequency')\nplt.ylabel('Density')\nplt.show()","metadata":{"papermill":{"duration":3.962729,"end_time":"2024-06-08T20:37:30.338532","exception":false,"start_time":"2024-06-08T20:37:26.375803","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-09T21:28:14.102104Z","iopub.execute_input":"2024-06-09T21:28:14.102646Z","iopub.status.idle":"2024-06-09T21:28:20.916801Z","shell.execute_reply.started":"2024-06-09T21:28:14.102605Z","shell.execute_reply":"2024-06-09T21:28:20.915602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CLUSTERING\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ndf_scaled = scaler.fit_transform(df[['last_purchase_date', 'Frequency', 'TotalAmount']])","metadata":{"execution":{"iopub.status.busy":"2024-06-09T21:27:45.329407Z","iopub.execute_input":"2024-06-09T21:27:45.329967Z","iopub.status.idle":"2024-06-09T21:27:45.374498Z","shell.execute_reply.started":"2024-06-09T21:27:45.329923Z","shell.execute_reply":"2024-06-09T21:27:45.373000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#K-Means CLustering\nfrom sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters = 3)\nkmeans.fit(df_scaled)\n\ndf['Cluster'] = kmeans.labels_","metadata":{"execution":{"iopub.status.busy":"2024-06-09T21:28:52.251786Z","iopub.execute_input":"2024-06-09T21:28:52.252433Z","iopub.status.idle":"2024-06-09T21:28:53.894696Z","shell.execute_reply.started":"2024-06-09T21:28:52.252367Z","shell.execute_reply":"2024-06-09T21:28:53.892981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing Clusters\nplt.figure(figsize=(12, 6))\nsns.scatterplot(x='last_purchase_date', y='Frequency', hue='Cluster' , data=df)\nplt.title('Customer Segments')\nplt.xlabel('Last Purchase Date')\nplt.ylabel('Frequncy')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T21:29:23.873795Z","iopub.execute_input":"2024-06-09T21:29:23.876182Z","iopub.status.idle":"2024-06-09T21:29:51.870536Z","shell.execute_reply.started":"2024-06-09T21:29:23.876107Z","shell.execute_reply":"2024-06-09T21:29:51.869295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Analysing\ncluster_summary = df.groupby('Cluster').agg({\n    'last_purchase_date': 'mean',\n    'Frequency': 'mean',\n    'TotalAmount': 'mean',\n    'CustomerID': 'count'\n}).rename(columns={'CustomerID': 'Count'}).reset_index()\n\nprint(\"Cluster Summary:\")\nprint(cluster_summary)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T21:33:34.155690Z","iopub.execute_input":"2024-06-09T21:33:34.156482Z","iopub.status.idle":"2024-06-09T21:33:34.202784Z","shell.execute_reply.started":"2024-06-09T21:33:34.156406Z","shell.execute_reply":"2024-06-09T21:33:34.201201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#adding recomendations for specific customer\n\ndef recommendation(customerID, df, cluster_column='Cluster', num_recommendations=5):\n    \n    cust_cluster = df.loc[df['CustomerID'] == customerID, cluster_column].iloc[0]\n    \n    similar_customer = df[df[cluster_column] == cust_cluster]\n    \n    items = similar_customer.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(num_recommendations).index\n    \n    recommendations = list(items)\n    print(\"Top\", num_recommendations, \"recommendations for Customer\", customerID, \":\")\n    for item in recommendations:\n        print(\"-\", item)\n    \n    return recommendations\n\n# Example: Recommend items for a specific customer\nCustomerID = '17850'  # Example customer ID\nrecommendations = recommendation(customerID, df)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T21:57:00.740019Z","iopub.execute_input":"2024-06-09T21:57:00.740587Z","iopub.status.idle":"2024-06-09T21:57:00.840547Z","shell.execute_reply.started":"2024-06-09T21:57:00.740542Z","shell.execute_reply":"2024-06-09T21:57:00.839226Z"},"trusted":true},"execution_count":null,"outputs":[]}]}